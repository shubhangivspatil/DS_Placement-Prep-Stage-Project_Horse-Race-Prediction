{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648c30d-c48e-40a2-ac47-4871f3c8bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing all the files\n",
    "data_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "\n",
    "# Function to load and check columns of horse and race data for a given year\n",
    "def load_and_check_columns(year, data_dir):\n",
    "    horse_file = os.path.join(data_dir, f'horses_{year}.csv')\n",
    "    race_file = os.path.join(data_dir, f'races_{year}.csv')\n",
    "    \n",
    "    if os.path.exists(horse_file) and os.path.exists(race_file):\n",
    "        horses = pd.read_csv(horse_file, low_memory=False)\n",
    "        races = pd.read_csv(race_file, low_memory=False)\n",
    "        \n",
    "        print(f\"Columns in horses_{year}.csv: {horses.columns}\")\n",
    "        print(f\"Columns in races_{year}.csv: {races.columns}\")\n",
    "    else:\n",
    "        print(f\"Files for year {year} not found.\")\n",
    "\n",
    "# Check columns for each year from 1990 to 2020\n",
    "for year in range(1990, 2021):\n",
    "    load_and_check_columns(year, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc4da99-9601-45da-b330-70bbbf7cfc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Directory containing all the files\n",
    "data_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "\n",
    "# Function to load and merge horse and race data for a given year\n",
    "def load_and_merge_yearly_data(year, data_dir):\n",
    "    horse_file = os.path.join(data_dir, f'horses_{year}.csv')\n",
    "    race_file = os.path.join(data_dir, f'races_{year}.csv')\n",
    "    \n",
    "    if os.path.exists(horse_file) and os.path.exists(race_file):\n",
    "        horses = pd.read_csv(horse_file, low_memory=False)\n",
    "        races = pd.read_csv(race_file, low_memory=False)\n",
    "        \n",
    "        # Ensure 'rid' exists in both datasets\n",
    "        if 'rid' in horses.columns and 'rid' in races.columns:\n",
    "            merged_data = pd.merge(horses, races, on='rid')\n",
    "            print(f\"Successfully merged data for year {year}\")\n",
    "            return merged_data\n",
    "        else:\n",
    "            print(f\"'rid' column not found in one of the files for year {year}. Skipping...\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Files for year {year} not found. Skipping...\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the files don't exist\n",
    "\n",
    "# Load and merge data from 1990 to 2020\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in range(1990, 2021):\n",
    "    yearly_data = load_and_merge_yearly_data(year, data_dir)\n",
    "    if not yearly_data.empty:\n",
    "        all_data = pd.concat([all_data, yearly_data], ignore_index=True)\n",
    "\n",
    "print(\"All yearly data loaded and merged.\")\n",
    "print(\"Columns in all_data:\", all_data.columns)\n",
    "\n",
    "# Load forward.csv\n",
    "forward_file = os.path.join(data_dir, 'forward.csv')\n",
    "forward_data = pd.read_csv(forward_file, low_memory=False)\n",
    "print(\"Forward data loaded.\")\n",
    "print(\"Columns in forward_data:\", forward_data.columns)\n",
    "\n",
    "# Ensure necessary columns exist in both datasets before merging\n",
    "merge_columns = ['course', 'title', 'rclass', 'horseName', 'trainerName', 'jockeyName']\n",
    "if all(col in all_data.columns for col in merge_columns) and all(col in forward_data.columns for col in merge_columns):\n",
    "    complete_data = pd.merge(all_data, forward_data, on=merge_columns, how='left')\n",
    "    print(\"Forward data merged with all yearly data.\")\n",
    "else:\n",
    "    print(\"One of the necessary columns not found in one of the datasets. Merging skipped.\")\n",
    "    complete_data = all_data\n",
    "\n",
    "# Select important columns that are present in the DataFrame\n",
    "important_columns = [\n",
    "    'rid', 'res_win', 'horseName', 'trainerName', 'jockeyName', 'date', 'course', 'age', 'weight', \n",
    "    'distance', 'condition', 'position', 'decimalPrice', 'RPR', 'TR', 'OR'\n",
    "]\n",
    "existing_columns = [col for col in important_columns if col in complete_data.columns]\n",
    "complete_data = complete_data.loc[:, existing_columns]\n",
    "print(\"Selected important columns.\")\n",
    "\n",
    "# Handle missing values\n",
    "complete_data.ffill(inplace=True)\n",
    "print(\"Handled missing values using forward fill.\")\n",
    "\n",
    "# Ensure date is in 'dd/mm/yy' format\n",
    "if 'date' in complete_data.columns:\n",
    "    complete_data['date'] = pd.to_datetime(complete_data['date'], errors='coerce')  # Handle parsing errors\n",
    "    complete_data['date'] = complete_data['date'].dt.strftime('%d/%m/%y')\n",
    "    print(\"Date column formatted to 'dd/mm/yy'.\")\n",
    "\n",
    "# Process distance column (convert to numeric meters if applicable)\n",
    "if 'distance' in complete_data.columns:\n",
    "    def convert_distance_to_meters(distance):\n",
    "        if isinstance(distance, str):\n",
    "            try:\n",
    "                # Handle format like \"1m2f\" (1 mile 2 furlongs)\n",
    "                if 'm' in distance and 'f' in distance:\n",
    "                    parts = distance.split('m')\n",
    "                    miles = int(parts[0])\n",
    "                    furlongs = int(parts[1].replace('f', ''))\n",
    "                    return miles * 1609 + furlongs * 201.168\n",
    "                # Handle format like \"1m\" (1 mile)\n",
    "                elif 'm' in distance:\n",
    "                    return int(distance.replace('m', '')) * 1609\n",
    "                # Handle format like \"2f\" (2 furlongs)\n",
    "                elif 'f' in distance:\n",
    "                    return int(distance.replace('f', '')) * 201.168\n",
    "            except ValueError:\n",
    "                # Return NaN if the format is invalid\n",
    "                return None\n",
    "        return distance  # Leave unchanged if already numeric or non-string\n",
    "\n",
    "    complete_data['distance'] = complete_data['distance'].apply(convert_distance_to_meters)\n",
    "    complete_data['distance'] = pd.to_numeric(complete_data['distance'], errors='coerce')\n",
    "    print(\"Distance column processed and converted to numeric meters.\")\n",
    "\n",
    "# Convert categorical variables to numerical representations and save mappings\n",
    "categorical_columns = ['course', 'trainerName', 'jockeyName']\n",
    "mappings = {}\n",
    "mapping_dir = os.path.join(data_dir, 'mappings')\n",
    "os.makedirs(mapping_dir, exist_ok=True)\n",
    "\n",
    "for column in categorical_columns:\n",
    "    if column in complete_data.columns:\n",
    "        # Encode categorical variables\n",
    "        complete_data[column] = complete_data[column].astype('category')\n",
    "        category_mapping = dict(enumerate(complete_data[column].cat.categories))\n",
    "        mappings[column] = category_mapping\n",
    "        \n",
    "        # Save individual mapping to a JSON file\n",
    "        mapping_file = os.path.join(mapping_dir, f'{column}_mapping.json')\n",
    "        with open(mapping_file, 'w') as f:\n",
    "            json.dump(category_mapping, f, indent=4)\n",
    "        print(f\"Mapping for '{column}' saved as '{mapping_file}'.\")\n",
    "\n",
    "# Save all mappings in a single JSON file\n",
    "all_mappings_file = os.path.join(mapping_dir, 'all_mappings.json')\n",
    "with open(all_mappings_file, 'w') as f:\n",
    "    json.dump(mappings, f, indent=4)\n",
    "print(f\"All mappings saved as '{all_mappings_file}'.\")\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "output_file = os.path.join(data_dir, 'cleaned_final_dataset.csv')\n",
    "complete_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Dataset creation completed and saved as 'cleaned_final_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9934e14f-6573-45c2-ba29-2a52fb95c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Function to add value labels on bars\n",
    "def add_value_labels(ax):\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.0f'),\n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                   ha='center', va='center',\n",
    "                   xytext=(0, 10),\n",
    "                   textcoords='offset points')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('D:/GUVI_Projects/My_Projects/new_horse/Horse/cleaned_final_dataset.csv', low_memory=True)\n",
    "\n",
    "# Ensure the columns are treated as strings\n",
    "df['course'] = df['course'].astype(str)\n",
    "df['trainerName'] = df['trainerName'].astype(str)\n",
    "df['jockeyName'] = df['jockeyName'].astype(str)\n",
    "\n",
    "# Handle missing values\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "df[numeric_cols] = imputer_numeric.fit_transform(df[numeric_cols])\n",
    "df[categorical_cols] = imputer_categorical.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Count the occurrences of each unique value in the columns\n",
    "course_counts = df['course'].value_counts().reset_index()\n",
    "trainer_counts = df['trainerName'].value_counts().reset_index()\n",
    "jockey_counts = df['jockeyName'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "course_counts.columns = ['course', 'count']\n",
    "trainer_counts.columns = ['trainerName', 'count']\n",
    "jockey_counts.columns = ['jockeyName', 'count']\n",
    "\n",
    "# Example mapping dictionaries (replace with actual mappings if available)\n",
    "trainer_name_mapping = {9907: \"Trainer A\", 15408: \"Trainer B\", 15396: \"Trainer C\"}\n",
    "jockey_name_mapping = {4783: \"Jockey A\", 4740: \"Jockey B\", 15750: \"Jockey C\"}\n",
    "\n",
    "# Replace IDs with names safely\n",
    "trainer_counts['trainerName'] = trainer_counts['trainerName'].apply(\n",
    "    lambda x: trainer_name_mapping[int(x)] if str(x).isdigit() and int(x) in trainer_name_mapping else x\n",
    ")\n",
    "jockey_counts['jockeyName'] = jockey_counts['jockeyName'].apply(\n",
    "    lambda x: jockey_name_mapping[int(x)] if str(x).isdigit() and int(x) in jockey_name_mapping else x\n",
    ")\n",
    "\n",
    "# Save mappings to a JSON file\n",
    "mapping_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse/mappings'\n",
    "os.makedirs(mapping_dir, exist_ok=True)\n",
    "\n",
    "# Prepare mappings for saving\n",
    "mappings = {\n",
    "    \"trainerName\": trainer_name_mapping,\n",
    "    \"jockeyName\": jockey_name_mapping\n",
    "}\n",
    "\n",
    "# Save the mappings to a JSON file\n",
    "mappings_file = os.path.join(mapping_dir, 'all_mappings.json')\n",
    "with open(mappings_file, 'w') as f:\n",
    "    json.dump(mappings, f, indent=4)\n",
    "print(f\"All mappings saved as '{mappings_file}'\")\n",
    "\n",
    "# Bar plots for categorical data\n",
    "def bar_plot(data, x, y, title, xlabel, ylabel, rotation=90):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(data=data, x=x, y=y, order=data.sort_values(y, ascending=False)[x])\n",
    "    plt.xticks(rotation=rotation, fontsize=10)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    add_value_labels(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Course Plot\n",
    "if not course_counts.empty:\n",
    "    bar_plot(course_counts.head(20), 'course', 'count', 'Top 20 Courses by Count', 'Course', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'course'.\")\n",
    "\n",
    "# Trainer Plot\n",
    "if not trainer_counts.empty:\n",
    "    bar_plot(trainer_counts.head(20), 'trainerName', 'count', 'Top 20 Trainers', 'Trainer Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'trainerName'.\")\n",
    "\n",
    "# Jockey Plot\n",
    "if not jockey_counts.empty:\n",
    "    bar_plot(jockey_counts.head(20), 'jockeyName', 'count', 'Top 20 Jockeys', 'Jockey Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'jockeyName'.\")\n",
    "\n",
    "# Additional Visualizations: Horse Names and Positions\n",
    "horse_counts = df['horseName'].value_counts().reset_index()\n",
    "horse_counts.columns = ['horseName', 'count']\n",
    "if not horse_counts.empty:\n",
    "    bar_plot(horse_counts.head(20), 'horseName', 'count', 'Top 20 Horses by Count', 'Horse Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'horseName'.\")\n",
    "\n",
    "position_counts = df['position'].value_counts().reset_index()\n",
    "position_counts.columns = ['position', 'count']\n",
    "if not position_counts.empty:\n",
    "    bar_plot(position_counts, 'position', 'count', 'Race Positions by Count', 'Position', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'position'.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Enhanced EDA: Correlation Analysis\n",
    "# --------------------------------------\n",
    "\n",
    "# Distribution plots for numeric columns\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[col], kde=True, bins=30, color=\"blue\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Correlation Matrix and Heatmap\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plots for Numeric Relationships\n",
    "# Reducing dataset for scatter plot to avoid legend issues\n",
    "subset_df = df.sample(1000)  # Adjust the sample size as necessary\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i + 1, len(numeric_cols)):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=subset_df, x=numeric_cols[i], y=numeric_cols[j], hue='position', palette=\"tab10\", legend=False)\n",
    "        plt.title(f\"Scatter Plot: {numeric_cols[i]} vs {numeric_cols[j]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# --------------------------------------\n",
    "# Feature Importance Analysis using Mutual Information\n",
    "# --------------------------------------\n",
    "\n",
    "# Encode categorical features for mutual information analysis\n",
    "encoded_df = df.copy()\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    encoded_df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Specify a target column for MI analysis\n",
    "target_column = 'res_win'  # Replace with your actual target column\n",
    "if target_column in df.columns:\n",
    "    mi_scores = mutual_info_classif(encoded_df[numeric_cols], encoded_df[target_column], discrete_features=False)\n",
    "    mi_df = pd.DataFrame({'Feature': numeric_cols, 'Mutual Information': mi_scores})\n",
    "    mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "    # Plot Mutual Information Scores\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=mi_df, x='Mutual Information', y='Feature', palette='viridis')\n",
    "    plt.title(\"Feature Importance using Mutual Information\")\n",
    "    plt.xlabel(\"Mutual Information Score\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Target column not found for mutual information analysis.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Interactive Plots using Plotly\n",
    "# --------------------------------------\n",
    "\n",
    "# Interactive plot for top 20 courses by count\n",
    "fig = px.bar(course_counts.head(20), x='course', y='count', title='Top 20 Courses by Count')\n",
    "fig.show()\n",
    "\n",
    "# Interactive plot for top 20 trainers by count\n",
    "fig = px.bar(trainer_counts.head(20), x='trainerName', y='count', title='Top 20 Trainers by Count')\n",
    "fig.show()\n",
    "\n",
    "# Interactive plot for top 20 jockeys by count\n",
    "fig = px.bar(jockey_counts.head(20), x='jockeyName', y='count', title='Top 20 Jockeys by Count')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9587edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Paths\n",
    "dataset_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse/cleaned_final_dataset.csv'\n",
    "save_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "model_save_path = os.path.join(save_path, 'horse_model.pkl')\n",
    "best_params_path = os.path.join(save_path, 'best_params.json')\n",
    "evaluation_metrics_path = os.path.join(save_path, 'evaluation_metrics.txt')\n",
    "mappings_file_path = os.path.join(save_path, 'mappings', 'all_mappings.json')\n",
    "\n",
    "# Function to optimize memory usage\n",
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type == 'float64' or col_type == 'float32':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'int64' or col_type == 'int32':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df\n",
    "\n",
    "# Load mappings\n",
    "with open(mappings_file_path, 'r') as f:\n",
    "    mappings = json.load(f)\n",
    "\n",
    "# Load data in chunks\n",
    "chunk_size = 100000\n",
    "chunks = pd.read_csv(\n",
    "    dataset_path, \n",
    "    chunksize=chunk_size, \n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Check if mappings are already applied\n",
    "sample_chunk = pd.read_csv(dataset_path, nrows=5)\n",
    "is_trainer_encoded = sample_chunk['trainerName'].dtype in ['int64', 'float64']\n",
    "is_jockey_encoded = sample_chunk['jockeyName'].dtype in ['int64', 'float64']\n",
    "\n",
    "if is_trainer_encoded and is_jockey_encoded:\n",
    "    print(\"Trainer and Jockey mappings are already applied in the dataset. Skipping encoding step.\")\n",
    "else:\n",
    "    print(\"Trainer and Jockey mappings are not applied. Encoding now.\")\n",
    "\n",
    "# Process and combine chunks\n",
    "processed_chunks = []\n",
    "for chunk in chunks:\n",
    "    # Drop irrelevant columns\n",
    "    chunk.drop(['horseName', 'date', 'rid'], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply mappings only if not already encoded\n",
    "    if not is_trainer_encoded:\n",
    "        chunk['trainerName'] = chunk['trainerName'].map(lambda x: mappings['trainerName'].get(str(x), -1))\n",
    "    if not is_jockey_encoded:\n",
    "        chunk['jockeyName'] = chunk['jockeyName'].map(lambda x: mappings['jockeyName'].get(str(x), -1))\n",
    "    \n",
    "    # Encode other categorical columns\n",
    "    if 'course' in chunk.columns:\n",
    "        chunk['course'] = chunk['course'].map(lambda x: mappings.get('course', {}).get(str(x), -1))\n",
    "    \n",
    "    # Feature Engineering\n",
    "    chunk['speed_ratio'] = chunk['distance'] / (chunk['position'] + 1)  # Example feature\n",
    "    chunk['success_rate'] = chunk['RPR'] / (chunk['TR'] + 1)  # Prevent division by zero\n",
    "    \n",
    "    # Replace infinities and handle missing values\n",
    "    chunk.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Separate numeric and non-numeric columns\n",
    "    numeric_cols = chunk.select_dtypes(include=[np.number]).columns\n",
    "    non_numeric_cols = chunk.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "    # Handle missing values separately\n",
    "    chunk[numeric_cols] = chunk[numeric_cols].fillna(chunk[numeric_cols].median())\n",
    "    chunk[non_numeric_cols] = chunk[non_numeric_cols].fillna(\"Unknown\")\n",
    "    \n",
    "    # Optimize memory\n",
    "    chunk = optimize_memory(chunk)\n",
    "    \n",
    "    processed_chunks.append(chunk)\n",
    "\n",
    "# Combine processed chunks\n",
    "data = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "# Drop low-variance features\n",
    "low_variance_cols = [col for col in data.columns if data[col].nunique() == 1]\n",
    "data.drop(columns=low_variance_cols, inplace=True)\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(['res_win'], axis=1)\n",
    "y = data['res_win']\n",
    "\n",
    "# Scale features (numeric columns only)\n",
    "scaler = StandardScaler()\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "X[numeric_features] = scaler.fit_transform(X[numeric_features])\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Classifier with Hyperparameter Tuning\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and parameters\n",
    "best_rf = random_search.best_estimator_\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# Print and save the best parameters\n",
    "print(\"Best Parameters:\", best_params)\n",
    "with open(best_params_path, 'w') as f:\n",
    "    json.dump(best_params, f, indent=4)\n",
    "print(f\"Best parameters saved to: {best_params_path}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "\n",
    "# Log evaluation metrics\n",
    "with open(evaluation_metrics_path, 'w') as f:\n",
    "    f.write(\"Confusion Matrix:\\n\")\n",
    "    f.write(np.array2string(conf_matrix))\n",
    "    f.write(\"\\n\\nClassification Report:\\n\")\n",
    "    f.write(class_report)\n",
    "print(f\"Evaluation metrics saved to: {evaluation_metrics_path}\")\n",
    "\n",
    "# Save the model\n",
    "with open(model_save_path, 'wb') as f:\n",
    "    pickle.dump(best_rf, f)\n",
    "\n",
    "print(\"Model saved to:\", model_save_path)\n",
    "\n",
    "# Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
    "# Best Parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_depth': 30, 'bootstrap': False}\n",
    "# Best parameters saved to: D:/GUVI_Projects/My_Projects/new_horse/Horse\\best_params.json\n",
    "# Confusion Matrix:\n",
    "#  [[741781      0]\n",
    "#  [     0  79684]]\n",
    "\n",
    "# Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    741781\n",
    "#          1.0       1.00      1.00      1.00     79684\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n",
    "# Evaluation metrics saved to: D:/GUVI_Projects/My_Projects/new_horse/Horse\\evaluation_metrics.txt\n",
    "# Model saved to: D:/GUVI_Projects/My_Projects/new_horse/Horse\\horse_model.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dca589-5b93-4274-9430-6c858cdadaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "import json\n",
    "\n",
    "# Set up logging\n",
    "log_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_dir, 'script_log.txt')\n",
    "logging.basicConfig(filename=log_file, level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Paths\n",
    "dataset_path = os.path.join(log_dir, 'cleaned_final_dataset.csv')\n",
    "cleaned_dataset_path = os.path.join(log_dir, 'cleaned_dataset_with_mappings.csv')\n",
    "mappings_file_path = os.path.join(log_dir, 'mappings.json')\n",
    "gb_model_save_path = os.path.join(log_dir, 'horse_gb_model.pkl')\n",
    "lr_model_save_path = os.path.join(log_dir, 'horse_lr_model.pkl')\n",
    "linear_model_save_path = os.path.join(log_dir, 'horse_linear_model.pkl')\n",
    "scaler_save_path = os.path.join(log_dir, 'scaler.pkl')\n",
    "\n",
    "# Function to log exceptions\n",
    "def log_exception(exc):\n",
    "    logging.error(f\"Exception occurred: {exc}\")\n",
    "    logging.error(\"\".join(traceback.format_exception(None, exc, exc.__traceback__)))\n",
    "\n",
    "# Function to clean and save the dataset\n",
    "def clean_dataset(data):\n",
    "    try:\n",
    "        print(\"Cleaning dataset...\")\n",
    "        for col in data.columns:\n",
    "            if pd.api.types.is_datetime64_any_dtype(data[col]) or 'date' in col.lower():\n",
    "                print(f\"Cleaning date column: {col}\")\n",
    "                # Specify the expected format, e.g., '%Y-%m-%d' for '2024-12-31'\n",
    "                try:\n",
    "                    data[col] = pd.to_datetime(data[col], format='%Y-%m-%d', errors='coerce')\n",
    "                except ValueError:\n",
    "                    # Fallback to auto-detection if the format is unknown\n",
    "                    data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "                min_date = data[col].min()\n",
    "                data[col] = data[col].fillna(min_date)\n",
    "            elif data[col].dtype == 'object':\n",
    "                print(f\"Cleaning categorical column: {col}\")\n",
    "                data[col] = data[col].fillna('Unknown')\n",
    "            else:\n",
    "                print(f\"Cleaning numeric column: {col}\")\n",
    "                data[col] = pd.to_numeric(data[col], errors='coerce')\n",
    "                median_value = data[col].median()\n",
    "                data[col] = data[col].fillna(median_value)\n",
    "\n",
    "        # Feature Engineering\n",
    "        if 'distance' in data.columns and 'position' in data.columns:\n",
    "            data['speed_ratio'] = data['distance'] / (data['position'] + 1)\n",
    "        if 'RPR' in data.columns and 'TR' in data.columns:\n",
    "            data['success_rate'] = data['RPR'] / (data['TR'] + 1)\n",
    "\n",
    "        print(\"Dataset cleaned successfully. Saving...\")\n",
    "        data.to_csv(dataset_path, index=False)\n",
    "        logging.info(\"Dataset cleaned and saved successfully.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        log_exception(e)\n",
    "        raise\n",
    "\n",
    "# Function to create mappings for categorical columns\n",
    "def create_mappings(data, categorical_columns):\n",
    "    try:\n",
    "        mappings = {}\n",
    "        for col in categorical_columns:\n",
    "            print(f\"Creating mappings for column: {col}\")\n",
    "            unique_mapping = {val: idx for idx, val in enumerate(data[col].astype(str).unique())}\n",
    "            mappings[col] = unique_mapping\n",
    "            data[col] = data[col].map(unique_mapping)\n",
    "        with open(mappings_file_path, 'w') as f:\n",
    "            json.dump(mappings, f, indent=4)\n",
    "        logging.info(\"Mappings created and saved successfully.\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        log_exception(e)\n",
    "        raise\n",
    "\n",
    "# Load and clean dataset\n",
    "try:\n",
    "    data = pd.read_csv(dataset_path)\n",
    "    data = clean_dataset(data)\n",
    "    categorical_columns = ['horseName', 'trainerName', 'jockeyName', 'course']\n",
    "    data = create_mappings(data, categorical_columns)\n",
    "    data.to_csv(cleaned_dataset_path, index=False)\n",
    "except Exception as e:\n",
    "    log_exception(e)\n",
    "    raise\n",
    "\n",
    "# Model training and evaluation\n",
    "try:\n",
    "    # Define target and features\n",
    "    X = data.drop(['res_win'], axis=1)\n",
    "    y = data['res_win']\n",
    "\n",
    "    # Identify numeric columns\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    X_numeric = X[numeric_features]\n",
    "\n",
    "    # Log sample sizes\n",
    "    print(f\"Dataset samples: {len(data)}, Training samples: {int(len(X_numeric) * 0.8)}, Testing samples: {int(len(X_numeric) * 0.2)}\")\n",
    "    logging.info(f\"Dataset samples: {len(data)}, Training samples: {int(len(X_numeric) * 0.8)}, Testing samples: {int(len(X_numeric) * 0.2)}\")\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_numeric, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    with open(scaler_save_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "\n",
    "    # Balancing the dataset with SMOTETomek and undersampling\n",
    "    smote_tomek = SMOTETomek(random_state=42)\n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    # Gradient Boosting Classifier with enhanced regularization\n",
    "    gb = GradientBoostingClassifier(random_state=42)\n",
    "    gb_param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 3]\n",
    "    }\n",
    "    gb_random_search = RandomizedSearchCV(\n",
    "        gb, gb_param_grid, n_iter=10, cv=5, random_state=42, n_jobs=-1, verbose=2\n",
    "    )\n",
    "    gb_pipeline = Pipeline(steps=[\n",
    "        ('undersample', undersampler),\n",
    "        ('smote', smote_tomek),\n",
    "        ('classifier', gb_random_search)\n",
    "    ])\n",
    "    gb_pipeline.fit(X_train_scaled, y_train)\n",
    "    best_gb_model = gb_random_search.best_estimator_\n",
    "    print(\"\\nBest Parameters for Gradient Boosting:\")\n",
    "    print(gb_random_search.best_params_)\n",
    "    with open(gb_model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_gb_model, f)\n",
    "\n",
    "    # Logistic Regression with enhanced regularization\n",
    "    lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    lr_param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    }\n",
    "    lr_random_search = RandomizedSearchCV(\n",
    "        lr, lr_param_grid, n_iter=10, cv=5, random_state=42, n_jobs=-1, verbose=2\n",
    "    )\n",
    "    lr_pipeline = Pipeline(steps=[\n",
    "        ('undersample', undersampler),\n",
    "        ('smote', smote_tomek),\n",
    "        ('classifier', lr_random_search)\n",
    "    ])\n",
    "    lr_pipeline.fit(X_train_scaled, y_train)\n",
    "    best_lr_model = lr_random_search.best_estimator_\n",
    "    print(\"\\nBest Parameters for Logistic Regression:\")\n",
    "    print(lr_random_search.best_params_)\n",
    "    with open(lr_model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_lr_model, f)\n",
    "\n",
    "    # Ridge Regression (L2 regularization)\n",
    "    ridge_model = Ridge(alpha=1.0)  # Regularization strength\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "    with open(linear_model_save_path, 'wb') as f:\n",
    "        pickle.dump(ridge_model, f)\n",
    "\n",
    "    logging.info(\"All models trained and saved successfully.\")\n",
    "except Exception as e:\n",
    "    log_exception(e)\n",
    "    raise\n",
    "\n",
    "# Model evaluation\n",
    "try:\n",
    "    # Gradient Boosting\n",
    "    y_pred_gb = best_gb_model.predict(X_test_scaled)\n",
    "    print(\"\\nConfusion Matrix for Gradient Boosting:\")\n",
    "    print(confusion_matrix(y_test, y_pred_gb))\n",
    "    print(\"\\nClassification Report for Gradient Boosting:\")\n",
    "    print(classification_report(y_test, y_pred_gb))\n",
    "\n",
    "    # Logistic Regression\n",
    "    y_pred_lr = best_lr_model.predict(X_test_scaled)\n",
    "    print(\"\\nConfusion Matrix for Logistic Regression:\")\n",
    "    print(confusion_matrix(y_test, y_pred_lr))\n",
    "    print(\"\\nClassification Report for Logistic Regression:\")\n",
    "    print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "    # Ridge Regression\n",
    "    y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred_ridge)\n",
    "    r2 = r2_score(y_test, y_pred_ridge)\n",
    "    print(\"\\nRidge Regression Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\")\n",
    "except Exception as e:\n",
    "    log_exception(e)\n",
    "    raise\n",
    "# Best Parameters for Gradient Boosting:\n",
    "# {'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 5, 'learning_rate': 0.1}\n",
    "# Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "\n",
    "# Best Parameters for Logistic Regression:\n",
    "# {'solver': 'liblinear', 'penalty': 'l1', 'C': 0.01}\n",
    "\n",
    "# Confusion Matrix for Gradient Boosting:\n",
    "# [[742297      0]\n",
    "#  [     0  79168]]\n",
    "\n",
    "# Classification Report for Gradient Boosting:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    742297\n",
    "#          1.0       1.00      1.00      1.00     79168\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n",
    "\n",
    "# Confusion Matrix for Logistic Regression:\n",
    "# [[742187    110]\n",
    "#  [     0  79168]]\n",
    "\n",
    "# Classification Report for Logistic Regression:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    742297\n",
    "#          1.0       1.00      1.00      1.00     79168\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n",
    "\n",
    "# Ridge Regression Performance:\n",
    "# Mean Squared Error: 0.0406\n",
    "# R² Score: 0.5340\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a372fc7-ca24-438f-8142-41c061b86b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
