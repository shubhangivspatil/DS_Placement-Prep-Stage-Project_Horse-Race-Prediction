{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648c30d-c48e-40a2-ac47-4871f3c8bc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing all the files\n",
    "data_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "\n",
    "# Function to load and check columns of horse and race data for a given year\n",
    "def load_and_check_columns(year, data_dir):\n",
    "    horse_file = os.path.join(data_dir, f'horses_{year}.csv')\n",
    "    race_file = os.path.join(data_dir, f'races_{year}.csv')\n",
    "    \n",
    "    if os.path.exists(horse_file) and os.path.exists(race_file):\n",
    "        horses = pd.read_csv(horse_file, low_memory=False)\n",
    "        races = pd.read_csv(race_file, low_memory=False)\n",
    "        \n",
    "        print(f\"Columns in horses_{year}.csv: {horses.columns}\")\n",
    "        print(f\"Columns in races_{year}.csv: {races.columns}\")\n",
    "    else:\n",
    "        print(f\"Files for year {year} not found.\")\n",
    "\n",
    "# Check columns for each year from 1990 to 2020\n",
    "for year in range(1990, 2021):\n",
    "    load_and_check_columns(year, data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db4a07-92a5-4f3a-a66c-add8bd41ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Directory containing all the files\n",
    "data_dir = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "\n",
    "# Function to load and merge horse and race data for a given year\n",
    "def load_and_merge_yearly_data(year, data_dir):\n",
    "    horse_file = os.path.join(data_dir, f'horses_{year}.csv')\n",
    "    race_file = os.path.join(data_dir, f'races_{year}.csv')\n",
    "    \n",
    "    if os.path.exists(horse_file) and os.path.exists(race_file):\n",
    "        horses = pd.read_csv(horse_file, low_memory=False)\n",
    "        races = pd.read_csv(race_file, low_memory=False)\n",
    "        \n",
    "        # Ensure 'rid' exists in both datasets\n",
    "        if 'rid' in horses.columns and 'rid' in races.columns:\n",
    "            merged_data = pd.merge(horses, races, on='rid')\n",
    "            print(f\"Successfully merged data for year {year}\")\n",
    "            return merged_data\n",
    "        else:\n",
    "            print(f\"'rid' column not found in one of the files for year {year}. Skipping...\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Files for year {year} not found. Skipping...\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the files don't exist\n",
    "\n",
    "# Load and merge data from 1990 to 2020\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for year in range(1990, 2021):\n",
    "    yearly_data = load_and_merge_yearly_data(year, data_dir)\n",
    "    if not yearly_data.empty:\n",
    "        all_data = pd.concat([all_data, yearly_data], ignore_index=True)\n",
    "\n",
    "print(\"All yearly data loaded and merged.\")\n",
    "print(\"Columns in all_data:\", all_data.columns)\n",
    "\n",
    "# Load forward.csv\n",
    "forward_file = os.path.join(data_dir, 'forward.csv')\n",
    "forward_data = pd.read_csv(forward_file, low_memory=False)\n",
    "print(\"Forward data loaded.\")\n",
    "print(\"Columns in forward_data:\", forward_data.columns)\n",
    "\n",
    "# Ensure necessary columns exist in both datasets before merging\n",
    "merge_columns = ['course', 'title', 'rclass', 'horseName', 'trainerName', 'jockeyName']\n",
    "if all(col in all_data.columns for col in merge_columns) and all(col in forward_data.columns for col in merge_columns):\n",
    "    complete_data = pd.merge(all_data, forward_data, on=merge_columns, how='left')\n",
    "    print(\"Forward data merged with all yearly data.\")\n",
    "else:\n",
    "    print(\"One of the necessary columns not found in one of the datasets. Merging skipped.\")\n",
    "    complete_data = all_data\n",
    "\n",
    "# Select important columns that are present in the DataFrame\n",
    "important_columns = [\n",
    "    'rid', 'res_win', 'horseName', 'trainerName', 'jockeyName', 'date', 'course', 'age', 'weight', \n",
    "    'distance', 'condition', 'position', 'decimalPrice', 'RPR', 'TR', 'OR'\n",
    "]\n",
    "existing_columns = [col for col in important_columns if col in complete_data.columns]\n",
    "complete_data = complete_data.loc[:, existing_columns]\n",
    "print(\"Selected important columns.\")\n",
    "\n",
    "# Handle missing values\n",
    "complete_data.ffill(inplace=True)\n",
    "print(\"Handled missing values using forward fill.\")\n",
    "\n",
    "# Ensure date is in 'dd/mm/yy' format\n",
    "if 'date' in complete_data.columns:\n",
    "    complete_data['date'] = pd.to_datetime(complete_data['date'], errors='coerce')  # Handle parsing errors\n",
    "    complete_data['date'] = complete_data['date'].dt.strftime('%d/%m/%y')\n",
    "    print(\"Date column formatted to 'dd/mm/yy'.\")\n",
    "\n",
    "# Process distance column (convert to numeric meters if applicable)\n",
    "if 'distance' in complete_data.columns:\n",
    "    def convert_distance_to_meters(distance):\n",
    "        if isinstance(distance, str):\n",
    "            try:\n",
    "                # Handle format like \"1m2f\" (1 mile 2 furlongs)\n",
    "                if 'm' in distance and 'f' in distance:\n",
    "                    parts = distance.split('m')\n",
    "                    miles = int(parts[0])\n",
    "                    furlongs = int(parts[1].replace('f', ''))\n",
    "                    return miles * 1609 + furlongs * 201.168\n",
    "                # Handle format like \"1m\" (1 mile)\n",
    "                elif 'm' in distance:\n",
    "                    return int(distance.replace('m', '')) * 1609\n",
    "                # Handle format like \"2f\" (2 furlongs)\n",
    "                elif 'f' in distance:\n",
    "                    return int(distance.replace('f', '')) * 201.168\n",
    "            except ValueError:\n",
    "                # Return NaN if the format is invalid\n",
    "                return None\n",
    "        return distance  # Leave unchanged if already numeric or non-string\n",
    "\n",
    "    complete_data['distance'] = complete_data['distance'].apply(convert_distance_to_meters)\n",
    "    complete_data['distance'] = pd.to_numeric(complete_data['distance'], errors='coerce')\n",
    "    print(\"Distance column processed and converted to numeric meters.\")\n",
    "\n",
    "# Convert categorical variables to numerical representations\n",
    "categorical_columns = ['course', 'trainerName', 'jockeyName']\n",
    "for column in categorical_columns:\n",
    "    if column in complete_data.columns:\n",
    "        complete_data[column] = complete_data[column].astype('category').cat.codes\n",
    "print(\"Encoded categorical variables to numerical representations.\")\n",
    "\n",
    "# Save the final cleaned dataset\n",
    "output_file = os.path.join(data_dir, 'cleaned_final_dataset.csv')\n",
    "complete_data.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Dataset creation completed and saved as 'cleaned_final_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613c0b2-2858-4bc2-876a-5794ef5e269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Function to add value labels on bars\n",
    "def add_value_labels(ax):\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(format(p.get_height(), '.0f'),\n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                   ha='center', va='center',\n",
    "                   xytext=(0, 10),\n",
    "                   textcoords='offset points')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('D:/GUVI_Projects/My_Projects/new_horse/Horse/cleaned_final_dataset.csv', low_memory=True)\n",
    "\n",
    "# Ensure the columns are treated as strings\n",
    "df['course'] = df['course'].astype(str)\n",
    "df['trainerName'] = df['trainerName'].astype(str)\n",
    "df['jockeyName'] = df['jockeyName'].astype(str)\n",
    "\n",
    "# Handle missing values\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute missing values\n",
    "imputer_numeric = SimpleImputer(strategy='mean')\n",
    "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "df[numeric_cols] = imputer_numeric.fit_transform(df[numeric_cols])\n",
    "df[categorical_cols] = imputer_categorical.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Count the occurrences of each unique value in the columns\n",
    "course_counts = df['course'].value_counts().reset_index()\n",
    "trainer_counts = df['trainerName'].value_counts().reset_index()\n",
    "jockey_counts = df['jockeyName'].value_counts().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "course_counts.columns = ['course', 'count']\n",
    "trainer_counts.columns = ['trainerName', 'count']\n",
    "jockey_counts.columns = ['jockeyName', 'count']\n",
    "\n",
    "# Example mapping dictionaries (replace with actual mappings if available)\n",
    "trainer_name_mapping = {9907: \"Trainer A\", 15408: \"Trainer B\", 15396: \"Trainer C\"}\n",
    "jockey_name_mapping = {4783: \"Jockey A\", 4740: \"Jockey B\", 15750: \"Jockey C\"}\n",
    "\n",
    "# Replace IDs with names\n",
    "trainer_counts['trainerName'] = trainer_counts['trainerName'].astype(int).map(trainer_name_mapping).fillna(trainer_counts['trainerName'])\n",
    "jockey_counts['jockeyName'] = jockey_counts['jockeyName'].astype(int).map(jockey_name_mapping).fillna(jockey_counts['jockeyName'])\n",
    "\n",
    "# Bar plots for categorical data\n",
    "def bar_plot(data, x, y, title, xlabel, ylabel, rotation=90):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(data=data, x=x, y=y, order=data.sort_values(y, ascending=False)[x])\n",
    "    plt.xticks(rotation=rotation, fontsize=10)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    add_value_labels(ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Course Plot\n",
    "if not course_counts.empty:\n",
    "    bar_plot(course_counts.head(20), 'course', 'count', 'Top 20 Courses by Count', 'Course', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'course'.\")\n",
    "\n",
    "# Trainer Plot\n",
    "if not trainer_counts.empty:\n",
    "    bar_plot(trainer_counts.head(20), 'trainerName', 'count', 'Top 20 Trainers', 'Trainer Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'trainerName'.\")\n",
    "\n",
    "# Jockey Plot\n",
    "if not jockey_counts.empty:\n",
    "    bar_plot(jockey_counts.head(20), 'jockeyName', 'count', 'Top 20 Jockeys', 'Jockey Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'jockeyName'.\")\n",
    "\n",
    "# Additional Visualizations: Horse Names and Positions\n",
    "horse_counts = df['horseName'].value_counts().reset_index()\n",
    "horse_counts.columns = ['horseName', 'count']\n",
    "if not horse_counts.empty:\n",
    "    bar_plot(horse_counts.head(20), 'horseName', 'count', 'Top 20 Horses by Count', 'Horse Name', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'horseName'.\")\n",
    "\n",
    "position_counts = df['position'].value_counts().reset_index()\n",
    "position_counts.columns = ['position', 'count']\n",
    "if not position_counts.empty:\n",
    "    bar_plot(position_counts, 'position', 'count', 'Race Positions by Count', 'Position', 'Count')\n",
    "else:\n",
    "    print(\"No data available for 'position'.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Enhanced EDA: Correlation Analysis\n",
    "# --------------------------------------\n",
    "\n",
    "# Distribution plots for numeric columns\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[col], kde=True, bins=30, color=\"blue\")\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Correlation Matrix and Heatmap\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plots for Numeric Relationships\n",
    "# Reducing dataset for scatter plot to avoid legend issues\n",
    "subset_df = df.sample(1000)  # Adjust the sample size as necessary\n",
    "for i in range(len(numeric_cols)):\n",
    "    for j in range(i + 1, len(numeric_cols)):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(data=subset_df, x=numeric_cols[i], y=numeric_cols[j], hue='position', palette=\"tab10\", legend=False)\n",
    "        plt.title(f\"Scatter Plot: {numeric_cols[i]} vs {numeric_cols[j]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# --------------------------------------\n",
    "# Feature Importance Analysis using Mutual Information\n",
    "# --------------------------------------\n",
    "\n",
    "# Encode categorical features for mutual information analysis\n",
    "encoded_df = df.copy()\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    encoded_df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Specify a target column for MI analysis\n",
    "target_column = 'res_win'  # Replace with your actual target column\n",
    "if target_column in df.columns:\n",
    "    mi_scores = mutual_info_classif(encoded_df[numeric_cols], encoded_df[target_column], discrete_features=False)\n",
    "    mi_df = pd.DataFrame({'Feature': numeric_cols, 'Mutual Information': mi_scores})\n",
    "    mi_df = mi_df.sort_values(by='Mutual Information', ascending=False)\n",
    "\n",
    "    # Plot Mutual Information Scores\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(data=mi_df, x='Mutual Information', y='Feature', palette='viridis')\n",
    "    plt.title(\"Feature Importance using Mutual Information\")\n",
    "    plt.xlabel(\"Mutual Information Score\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Target column not found for mutual information analysis.\")\n",
    "\n",
    "# --------------------------------------\n",
    "# Interactive Plots using Plotly\n",
    "# --------------------------------------\n",
    "\n",
    "# Interactive plot for top 20 courses by count\n",
    "fig = px.bar(course_counts.head(20), x='course', y='count', title='Top 20 Courses by Count')\n",
    "fig.show()\n",
    "\n",
    "# Interactive plot for top 20 trainers by count\n",
    "fig = px.bar(trainer_counts.head(20), x='trainerName', y='count', title='Top 20 Trainers by Count')\n",
    "fig.show()\n",
    "\n",
    "# Interactive plot for top 20 jockeys by count\n",
    "fig = px.bar(jockey_counts.head(20), x='jockeyName', y='count', title='Top 20 Jockeys by Count')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9587edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "dataset_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse/cleaned_final_dataset.csv'\n",
    "save_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "model_save_path = os.path.join(save_path, 'horse_model.pkl')\n",
    "\n",
    "# Function to optimize memory usage\n",
    "def optimize_memory(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type == 'float64' or col_type == 'float32':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "        elif col_type == 'int64' or col_type == 'int32':\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    return df\n",
    "\n",
    "# Load data in chunks and handle mixed types\n",
    "chunk_size = 100000  # Define chunk size\n",
    "chunks = pd.read_csv(\n",
    "    dataset_path, \n",
    "    chunksize=chunk_size, \n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "# Process and combine chunks\n",
    "processed_chunks = []\n",
    "for chunk in chunks:\n",
    "    # Drop irrelevant columns\n",
    "    chunk.drop(['horseName', 'date', 'rid'], axis=1, inplace=True)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    le_trainer = LabelEncoder()\n",
    "    le_jockey = LabelEncoder()\n",
    "    chunk['trainerName'] = le_trainer.fit_transform(chunk['trainerName'])\n",
    "    chunk['jockeyName'] = le_jockey.fit_transform(chunk['jockeyName'])\n",
    "    \n",
    "    # Feature Engineering\n",
    "    chunk['speed_ratio'] = chunk['distance'] / (chunk['position'] + 1)  # Example feature\n",
    "    chunk['success_rate'] = chunk['RPR'] / (chunk['TR'] + 1)  # Prevent division by zero\n",
    "    \n",
    "    # Replace infinities and large values\n",
    "    chunk.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    chunk.fillna(chunk.median(), inplace=True)  # Handle missing values\n",
    "    \n",
    "    # Optimize memory\n",
    "    chunk = optimize_memory(chunk)\n",
    "    \n",
    "    processed_chunks.append(chunk)\n",
    "\n",
    "# Combine processed chunks\n",
    "data = pd.concat(processed_chunks, ignore_index=True)\n",
    "\n",
    "# Drop low-variance features\n",
    "low_variance_cols = [col for col in data.columns if data[col].nunique() == 1]\n",
    "data.drop(columns=low_variance_cols, inplace=True)\n",
    "\n",
    "# Define target and features\n",
    "X = data.drop(['res_win'], axis=1)\n",
    "y = data['res_win']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Random Forest Classifier with Hyperparameter Tuning\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n",
    "                                   n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_rf.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Save the model\n",
    "with open(model_save_path, 'wb') as f:\n",
    "    pickle.dump(best_rf, f)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "# Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
    "# Confusion Matrix:\n",
    "#  [[741781      0]\n",
    "#  [     0  79684]]\n",
    "\n",
    "# Classification Report:\n",
    "#                precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    741781\n",
    "#          1.0       1.00      1.00      1.00     79684\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n",
    "# Model saved to: D:/GUVI_Projects/My_Projects/new_horse/Horse\\horse_model.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f1a63-b65c-4e2c-b6fc-2e4b03b239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "import traceback\n",
    "\n",
    "# Set up logging\n",
    "log_file = 'D:/GUVI_Projects/My_Projects/new_horse/Horse/script_log.txt'\n",
    "logging.basicConfig(filename=log_file, level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to log exceptions\n",
    "def log_exception(exc):\n",
    "    logging.error(f\"Exception occurred: {exc}\")\n",
    "    logging.error(\"\".join(traceback.format_exception(None, exc, exc.__traceback__)))\n",
    "\n",
    "# Paths\n",
    "dataset_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse/cleaned_final_dataset.csv'\n",
    "save_path = 'D:/GUVI_Projects/My_Projects/new_horse/Horse'\n",
    "gb_model_save_path = os.path.join(save_path, 'horse_gb_model.pkl')\n",
    "lr_model_save_path = os.path.join(save_path, 'horse_lr_model.pkl')\n",
    "processed_chunks_path = os.path.join(save_path, 'processed_chunks')\n",
    "\n",
    "os.makedirs(processed_chunks_path, exist_ok=True)\n",
    "\n",
    "# Function to optimize memory usage\n",
    "def optimize_memory(df):\n",
    "    try:\n",
    "        for col in df.columns:\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in ['float64', 'float32']:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "            elif col_type in ['int64', 'int32']:\n",
    "                df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "        logging.info(\"Memory optimization completed.\")\n",
    "    except Exception as e:\n",
    "        log_exception(e)\n",
    "        logging.error(\"Error during memory optimization.\")\n",
    "    return df\n",
    "\n",
    "# Initialize LabelEncoders\n",
    "le_trainer = LabelEncoder()\n",
    "le_jockey = LabelEncoder()\n",
    "\n",
    "chunk_size = 50000\n",
    "processed_chunks = []\n",
    "\n",
    "try:\n",
    "    for i, chunk in enumerate(pd.read_csv(dataset_path, chunksize=chunk_size, low_memory=False)):\n",
    "        try:\n",
    "            logging.info(f\"Processing chunk {i}...\")\n",
    "\n",
    "            # Ensure required columns exist\n",
    "            required_columns = ['trainerName', 'jockeyName', 'distance', 'position', 'RPR', 'TR', 'res_win']\n",
    "            if not all(col in chunk.columns for col in required_columns):\n",
    "                raise ValueError(f\"One or more required columns missing in chunk {i}\")\n",
    "\n",
    "            # Drop irrelevant columns\n",
    "            chunk.drop(['horseName', 'date', 'rid'], axis=1, errors='ignore', inplace=True)\n",
    "\n",
    "            # Encode categorical columns\n",
    "            chunk['trainerName'] = le_trainer.fit_transform(chunk['trainerName'])\n",
    "            chunk['jockeyName'] = le_jockey.fit_transform(chunk['jockeyName'])\n",
    "\n",
    "            # Feature Engineering\n",
    "            chunk['speed_ratio'] = chunk['distance'] / (chunk['position'] + 1)\n",
    "            chunk['success_rate'] = chunk['RPR'] / (chunk['TR'] + 1)\n",
    "\n",
    "            # Replace infinities and handle missing values\n",
    "            chunk.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            chunk.fillna(chunk.median(), inplace=True)\n",
    "\n",
    "            # Optimize memory\n",
    "            chunk = optimize_memory(chunk)\n",
    "\n",
    "            # Save processed chunk for future use\n",
    "            processed_chunks.append(chunk)\n",
    "            chunk.to_csv(os.path.join(processed_chunks_path, f'chunk_{i}.csv'), index=False)\n",
    "\n",
    "            logging.info(f\"Processed chunk {i} successfully.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            log_exception(e)\n",
    "            logging.warning(f\"Failed to process chunk {i}. Skipping this chunk.\")\n",
    "            continue\n",
    "\n",
    "    # Combine processed chunks\n",
    "    data = pd.concat(processed_chunks, ignore_index=True)\n",
    "    logging.info(\"Chunks combined successfully.\")\n",
    "\n",
    "    # Drop low-variance features\n",
    "    low_variance_cols = [col for col in data.columns if data[col].nunique() == 1]\n",
    "    data.drop(columns=low_variance_cols, inplace=True)\n",
    "\n",
    "    # Define target and features\n",
    "    X = data.drop(['res_win'], axis=1)\n",
    "    y = data['res_win']\n",
    "\n",
    "    logging.info(\"Data preparation completed.\")\n",
    "\n",
    "except Exception as e:\n",
    "    log_exception(e)\n",
    "    logging.error(\"Error during data preparation.\")\n",
    "\n",
    "try:\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    logging.info(\"Data split into training and testing sets.\")\n",
    "\n",
    "    # Define SMOTE and under-sampling\n",
    "    smote = SMOTE(random_state=42)\n",
    "    under_sampler = RandomUnderSampler(random_state=42)\n",
    "\n",
    "    # Gradient Boosting Classifier with Hyperparameter Tuning\n",
    "    gb = GradientBoostingClassifier(random_state=42)\n",
    "    gb_pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                  ('smote', smote),\n",
    "                                  ('under', under_sampler),\n",
    "                                  ('classifier', gb)])\n",
    "\n",
    "    gb_param_dist = {\n",
    "        'classifier__n_estimators': [100, 200, 300],\n",
    "        'classifier__learning_rate': [0.01, 0.05, 0.1],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "        'classifier__subsample': [0.8, 1.0],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        gb_random_search = RandomizedSearchCV(estimator=gb_pipeline, param_distributions=gb_param_dist,\n",
    "                                              n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "        gb_random_search.fit(X_train, y_train)\n",
    "        best_gb_pipeline = gb_random_search.best_estimator_\n",
    "\n",
    "        with open(gb_model_save_path, 'wb') as f:\n",
    "            pickle.dump(best_gb_pipeline, f)\n",
    "        logging.info(f\"Gradient Boosting model saved to: {gb_model_save_path}\")\n",
    "\n",
    "    except Exception as gb_e:\n",
    "        log_exception(gb_e)\n",
    "        logging.error(\"Gradient Boosting model training failed.\")\n",
    "        best_gb_pipeline = None\n",
    "\n",
    "    # Logistic Regression with Hyperparameter Tuning\n",
    "    lr = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "    lr_pipeline = Pipeline(steps=[('scaler', StandardScaler()),\n",
    "                                  ('smote', smote),\n",
    "                                  ('under', under_sampler),\n",
    "                                  ('classifier', lr)])\n",
    "\n",
    "    lr_param_dist = {\n",
    "        'classifier__C': [0.01, 0.1, 1, 10],\n",
    "        'classifier__solver': ['liblinear', 'lbfgs'],\n",
    "        'classifier__penalty': ['l2']\n",
    "    }\n",
    "\n",
    "    lr_random_search = RandomizedSearchCV(estimator=lr_pipeline, param_distributions=lr_param_dist,\n",
    "                                          n_iter=20, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    lr_random_search.fit(X_train, y_train)\n",
    "    best_lr_pipeline = lr_random_search.best_estimator_\n",
    "\n",
    "    with open(lr_model_save_path, 'wb') as f:\n",
    "        pickle.dump(best_lr_pipeline, f)\n",
    "    logging.info(f\"Logistic Regression model saved to: {lr_model_save_path}\")\n",
    "\n",
    "    # Evaluate models\n",
    "    if best_gb_pipeline:\n",
    "        logging.info(\"Evaluating Gradient Boosting model...\")\n",
    "        y_pred_gb = best_gb_pipeline.predict(X_test)\n",
    "        conf_matrix_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "        class_report_gb = classification_report(y_test, y_pred_gb)\n",
    "        logging.info(\"Gradient Boosting Confusion Matrix:\\n\" + str(conf_matrix_gb))\n",
    "        logging.info(\"Gradient Boosting Classification Report:\\n\" + class_report_gb)\n",
    "\n",
    "    logging.info(\"Evaluating Logistic Regression model...\")\n",
    "    y_pred_lr = best_lr_pipeline.predict(X_test)\n",
    "    conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "    class_report_lr = classification_report(y_test, y_pred_lr)\n",
    "    logging.info(\"Logistic Regression Confusion Matrix:\\n\" + str(conf_matrix_lr))\n",
    "    logging.info(\"Logistic Regression Classification Report:\\n\" + class_report_lr)\n",
    "\n",
    "except Exception as e:\n",
    "    log_exception(e)\n",
    "    logging.error(\"Error during model training and evaluation.\")\n",
    "\n",
    "\n",
    "\n",
    "# Gradient Boosting Confusion Matrix:\n",
    "# [[742297      0]\n",
    "#  [     0  79168]]\n",
    "# 2024-12-05 03:48:06,554 - INFO - Gradient Boosting Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    742297\n",
    "#          1.0       1.00      1.00      1.00     79168\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n",
    "# 2024-12-05 03:48:06,554 - INFO - Evaluating Logistic Regression model...\n",
    "# 2024-12-05 03:48:08,365 - INFO - Logistic Regression Confusion Matrix:\n",
    "# [[742187    110]\n",
    "#  [     0  79168]]\n",
    "# 2024-12-05 03:48:08,365 - INFO - Logistic Regression Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       1.00      1.00      1.00    742297\n",
    "#          1.0       1.00      1.00      1.00     79168\n",
    "\n",
    "#     accuracy                           1.00    821465\n",
    "#    macro avg       1.00      1.00      1.00    821465\n",
    "# weighted avg       1.00      1.00      1.00    821465\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8b55fd-5cc3-4260-990a-b2b2108a293e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca6e01-ef26-4231-8c4b-635f61f08f70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
